# Task 6: K-Nearest Neighbors (KNN) Classification

## ğŸ“˜ Project Overview
This project demonstrates how to implement **K-Nearest Neighbors (KNN)** for classification using the **Iris dataset**.  
The objective is to classify iris flowers based on sepal and petal measurements by comparing distance-based neighbors.  
This task focuses on normalization, experimenting with different values of `K`, and evaluating model accuracy.

---

## ğŸ§° Tools & Libraries Used
- **Python**
- **Pandas** â€“ for data handling  
- **NumPy** â€“ for mathematical operations  
- **Matplotlib / Seaborn** â€“ for visualization  
- **Scikit-learn** â€“ for model training and evaluation  

---

## ğŸ§© Steps Performed

### 1ï¸âƒ£ Import & Explore Data
- Loaded the Iris dataset using Pandas.  
- Checked for null values, data types, and dataset summary.

### 2ï¸âƒ£ Data Preprocessing
- Dropped unnecessary columns (`Id` if present).  
- Encoded target variable (`Species`) using LabelEncoder.  
- Standardized features using `StandardScaler` for equal weightage.

### 3ï¸âƒ£ Model Training (KNN)
- Trained **KNeighborsClassifier** from `sklearn`.  
- Tested `k` values from **1 to 20**.  
- Selected the best `k` based on **maximum accuracy**.

### 4ï¸âƒ£ Model Evaluation
- Evaluated model using:
  - âœ… **Accuracy Score**
  - âœ… **Confusion Matrix**
  - âœ… **Classification Report (Precision, Recall, F1-score)**
- Compared performance across `k` values.

### 5ï¸âƒ£ Visualization
- Plotted **Accuracy vs K** to find the best value.  
- Displayed **Decision Boundary** using the first two features to visualize class separation.

---

## ğŸ“Š Visualization Samples
| Visualization | Purpose |
|----------------|----------|
| `plt.plot(range(1,21), accuracy_scores)` | Compare accuracy for each K |
| `plt.contourf()` | Visualize decision boundaries between classes |
| `sns.heatmap(confusion_matrix)` | Display classification performance |

---

## âœ… Results
- Found the **optimal value of K** for best accuracy.  
- Achieved high classification accuracy on the Iris dataset.  
- Visualized clean class separation using the decision boundary.

---

## ğŸ’¾ Files Included
- `Iris.csv` â€” original dataset  
- `KNN_Classification.ipynb` â€” full project code  
- `README.md` â€” project documentation  

---

## ğŸ“š Learning Outcome
Through this task, I learned:
- How KNN works and how distance affects predictions.  
- How to tune hyperparameters (K value).  
- How to visualize and interpret classification boundaries.

---

## ğŸ§‘â€ğŸ’» Author
**Ganesh R**  
*(Junior AIML Engineer Trainee)*  
